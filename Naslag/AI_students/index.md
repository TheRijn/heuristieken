# Voor studenten uit de minor AI

> Deze tekst is bedoeld als introductie voor studenten van de minor AI die het vak Algoritmen en Heuristieken volgen, dat ook binnen de minor Programmeren wordt gegeven.

De algoritmen uit dit vak hebben een aantal belangrijke overeenkomsten, maar ook verschillen, met de machine learning algoritmen die jullie de afgelopen maanden hebben bestudeerd. Omdat Algoritmen en Heuristieken ook aan studenten van de minor Programmeren wordt gegeven, zullen deze overeenkomsten binnen het vak zelf niet worden behandeld. Deze tekst dient dus als supplement bij de lesstof, specifiek voor studenten die Algoritmen en Heuristieken starten met kennis van machine learning.

In de afgelopen vakken van de minor AI zijn jullie hoofdzakelijk bezig geweest met het leren van programmeren en machine learning, omdat machine learning de drijvende kracht is achter veel van de recente ontwikkelingen binnen AI. Zoals aan het begin van de minor besproken, is AI als vakgebied echter veel breder, en vallen daar allerlei soorten "intelligente" algoritmen onder. Typerend voor machine learning is dat de beste oplossing voor een probleem wordt _geleerd en geëvalueerd_ op basis van een grote dataset van voorbeelden, maar er zijn ook nog andere manieren om algoritmen slimmer te maken en oplossingen te vinden.

De algoritmen van dit vak vallen onder een klassieke tak binnen AI, namelijk de _zoek- en optimalisatie-algoritmen_. Hierbij is er geen grote data set met voorbeelden, maar is er alleen een _criterium_ dat aangeeft of een oplossing correct is, of rankschikt dat de ene oplossing beter is dan de andere. Dit criterium kan een simpele "objective function" zijn bijvoorbeeld, die aan elke mogelijk oplossing een score toekent. De uitdaging is daarbij om de beste oplossing, met de hoogste score (of juist de laagste), te vinden terwijl er zo veel potentiële oplossingen zijn dat ze allemaal proberen geen realistische aanpak meer is.

Het slim navigeren van _alle_ mogelijke oplossingen doe je hier door heuristieken toe te voegen, om zo de toestandsruimte die je moet doorzoeken te verkleinen. De intelligentie van deze algoritmen zit in het ontwerp van de algoritmen en heuristieken zelf. Omdat de cases voor dit vak alleen uit een beschrijving van het probleem bestaan, en dus ook geen trainingsvoorbeelden hebben, is het ook _niet mogelijk_ om hierop machine learning algoritmen op toe te passen. De cases zijn een fundamenteel ander soort probleem, en vereisen ook een andere aanpak.

Het is belangrijk om je bij dit vak te beperken tot de algoritmen die hier worden behandeld, en niet ook nog machine learning algoritmes te proberen toe te passen op de cases. Naast al deze verschillen, zijn ook een hoop overeenkomsten die je waarschijnlijk zult herkennen gedurende het vak. Zo lijkt een _objective function_ die een score aan een oplossing toekent natuurlijk heel erg op een _cost function_ voor supervised learning, alleen willen we daarbij de score maximaliseren in plaats van de cost te minimaliseren.

Het minimaliseren van de cost function hebben we altijd gedaan met een vorm van _gradient descent_, waarbij we de afgeleide van de cost function bepalen. De richting van de afgeleide bepaalt dan hoe de parameters van het model moeten worden aangepast om de kosten te verlagen. Door vanaf een willekeurig startpunt de parameters in de richting van de gradient aan te passen, hoeven we niet alle mogelijke verschillende combinaties van de parameterwaardes te proberen. Dit is dus ook een verkleining van het deel van de toestandsruimte die je hoeft te doorzoeken voor een optimale oplossing!

Bij een objective function is het meestal _niet mogelijk om de afgeleide te nemen_ ten opzichte van de verschillende parameters van de oplossing, want niet elke objective function of oplossingsparameter is even makkelijk differentieerbaar. Het optimaliseren moet dus op een andere manier, namelijk met een _hill climber_. Hierbij probeer je simpelweg een aantal aanpassingen en kijkt welke daarvan de score in de juiste richting beweegt. Je kiest hiervan dan de beste, en herhaalt dat proces vervolgens totdat je een geen verbeteringen meer kunt vinden. Deze herhaling is heel vergelijkbaar met gradient descent, maar dan ascent (omhoog) in plaats van descent (omlaag), en zonder een directe berekening van de gradiënt. De hill climber klimt omhoog op basis van beste uit een aantal geprobeerde veranderingen.

In de meer geavanceerde heuristieken algoritmen is nog wel verdere overlap met machine learning te vinden. Zo kan een hill climber natuurlijk ook vast komen te zitten in een lokaal maximum, en is het nuttig om het algoritme uit te breiden zodat de kans groter wordt dat het globale maximum wordt gevonden. Met deze introductie heb je hopelijk alvast een beeld van waar je wel en niet moet zoeken naar de overlap met machine learning algoritmen, voordat je begint met aanpakken van je eigen case.
